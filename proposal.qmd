---
title: "Method to the Madness"
subtitle: "Understanding NCAA Tournament Dynamics Through Data Visualization"
author: 
  - name: "Reagan Fleming - jrflemi5"
    affiliations:
      - name: "School of Information, University of Arizona"
description: "The aim of this project is to explore the relationship between public predictions and real outcomes in the NCAA Division 1 Men's Basketball Tournament. I will be leveraging datasets containing team performance metrics and public pick percentages"
format:
  html:
    code-tools: true
    code-overflow: wrap
    code-line-numbers: true
    embed-resources: true
editor: visual
code-annotations: hover
execute:
  warning: false
---

```{r}
#| label: load-pkgs
#| message: false
library(tidyverse)
library(readr)
```

## Dataset

```{r}
#| label: load-dataset
#| message: false
team_results <- read_csv("data/team-results.csv")
public_picks <- read_csv("data/public-picks.csv")
head(team_results)
head(public_picks)



```

A brief description of your dataset including its provenance, dimensions, etc. as well as the reason why you chose this dataset.

**Dataset Description:** this dataset contains 2 .csv files. One called team-results.csv and another called public-picks.csv. Team-results contains 'TEAMID' as the unique identifier or primary key as well as several attributes that quantify the team's performance in the tournament in each round. Team-results also quantifies the team's performance vs Komputer Expectations and Seed Expectations.

Public-picks.csv contains public prediction data for teams in the tournament. Public-picks contains 'TEAMNO' as the unique identifier or primary key. Public-picks contains several attributes quantifying the percent of people who picked that team to win each round of the tournament.

I chose this dataset for several reasons. I love sports, and wanted to use a dataset that is relevant to my personal interests in order to make this project more interesting. Any sports fan knows that "did you fill out your bracket?" dominates water cooler conversations in late February and early March. There are no recorded instances of someone making a perfect bracket prediction, and the odds of that happening are infinitesimal. When large numbers of crowds are attempting to predict unpredictable outcomes (gambling, the stock market) some interesting hivemind dynamics can come into play. One example, almost every year, a 12-seed team upsets a 5-seed team. One of the common questions asked when people fill out brackets is "who is your 12-5?" meaning: "of the 4 games in the first round in which a 12 seed plays a 5 seed, which 12 seed do you think will get the victory?" A quick google search shows that in the past 18 NCAA Tournaments, there have been 30 instances of a 12-5 upset. This equates to a 41.6% win percentage for a much lower seeded team. This seems unlikely, but happens with some regularity (almost half the time). I am also interested in discovering which teams, if any, consistently outperform or underperform fan expectations.

Make sure to load the data and use inline code for some of this information.

## Questions

The two questions you want to answer.

Q1: How accurate are public predictions in each round of the NCAA tournament compared to actual outcomes?

Q2: Which Men's College Basketball teams consistently outperform or underperform fan expectations/tournament seeding?

## Analysis plan

-   A plan for answering each of the questions including the variables involved, variables to be created (if any), external data to be merged in (if any).

Q1 plan: load the datasets into Rstudio. Ensure correct formatting. Dataframes may have to be merged on a common value (primary keys). Then for each team in each round I will compare the public pick percentages with the actual outcomes and determine metrics for prediction accuracy. My hypothesis is that as the rounds advance toward Final 4 and championship, public pick accuracy will decrease. I will then determine which visualizations will be most effective in communicating my findings

Q2 plan: Load and clean data from team-results.csv. Use PASE and PASERANK columns to determine how teams performed relative to seed expectations. Use data from public-picks.csv to determine how the team performed relative to crowd expectations. Identify which teams (if any) consistently over or underperform relative to seeding and crowd expectations. Then I will determine the appropriate ways to visualize this information.

## Plan of attack

| Task Name                        | Status   | Due  | Priority | Summary                                                                          |
|----------------------------------|----------|------|----------|----------------------------------------------------------------------------------|
| Import and clean dataset         | Not done | 5/31 | High     | Ensure data is appropriately imported for analysis                               |
| Explore dataset                  | Not done | 6/3  | High     | Conduct data exploration to understand attributes and relationships              |
| Transform and prep data          | Not done | 6/9  | High     | Prep data for analysis by ensuring all data is in clean format for processing    |
| "80%" solution for Q1            | Not done | 6/14 | High     | Establish effective comparison of public predictions to actual outcomes          |
| "80%" solution for Q2            | Not done | 6/18 | High     | Identify over and underperformers relative to seeding and public predictions     |
| Develop visualizations           | Not done | 6/21 | High     | Determine and develop appropriate visualizations to report findings              |
| Review and refine visualizations | Not done | 6/23 | High     | Give visualizations a "once over" to ensure they effectively present data        |
| Final report and presentation    | Not done | 6/24 | High     | Compile findings and visualizations into a comprehensive report for presentation |
